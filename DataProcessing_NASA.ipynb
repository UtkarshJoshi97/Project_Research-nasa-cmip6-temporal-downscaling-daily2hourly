{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11508881-0512-4a95-ad83-fa3a0d367159",
   "metadata": {},
   "source": [
    "### NASA NEX-GDDP Data Processing Script (Minnesota-Focused)\n",
    "\n",
    "link: S3 bucket - https://nex-gddp-cmip6.s3.us-west-2.amazonaws.com/index.html#NEX-GDDP-CMIP6/CNRM-CM6-1/\n",
    "\n",
    "This Python script processes daily NASA NEX-GDDP-CMIP6 climate data from **NetCDF files stored on AWS S3** into a clean, standardized dataset for **Minnesota**. It performs variable selection, spatial filtering, unit conversions, and outputs a combined CSV file ready for modeling or analysis.\n",
    "\n",
    "---\n",
    "\n",
    "#### Key Configuration\n",
    "\n",
    "- **Bounding Box:** Filters data for the Minnesota region  \n",
    "- **Years Processed:** 2021–2024  \n",
    "- **Variables Extracted:**\n",
    "  - `hurs` – Relative humidity  \n",
    "  - `pr` – Precipitation  \n",
    "  - `rlds`, `rsds` – Radiation (longwave and shortwave)  \n",
    "  - `sfcWind` – Surface wind speed  \n",
    "  - `tas`, `tasmax`, `tasmin` – Temperature metrics  \n",
    "\n",
    "---\n",
    "\n",
    "#### Core Logic & Workflow\n",
    "\n",
    "#####  1. Data Fetching from S3\n",
    "- Connects anonymously to **NASA NEX-GDDP-CMIP6** bucket on S3\n",
    "- Downloads daily NetCDF files for each variable and year to temporary storage\n",
    "- Loads files into `xarray` for efficient handling\n",
    "\n",
    "#####  2. Concatenation & Merging\n",
    "- Combines all years per variable into a single `xarray.Dataset`\n",
    "- Merges all variables into one comprehensive dataset\n",
    "\n",
    "#####  3. Spatial Filtering (Minnesota)\n",
    "- Applies latitude & longitude masks to isolate Minnesota\n",
    "- Converts spatial data to tabular format with `stack` + `to_dataframe()`\n",
    "\n",
    "#####  4. Unit Conversion & Cleaning\n",
    "- Converts:\n",
    "- `pr` → `precip_daily_mm` (kg/m²/s → mm/day)\n",
    "- Drops null/duplicate rows and resets the index for clean output\n",
    "\n",
    "#####  5. Output\n",
    "- Saves processed data as:\n",
    "- Located at a user-defined path (via `ROOT_DATA_DIR`)\n",
    "\n",
    "##### 6. Cleanup\n",
    "- Releases file handles, deletes temporary NetCDF files, and runs garbage collection\n",
    "\n",
    "---\n",
    "\n",
    "##### Dependencies\n",
    "\n",
    "- `xarray`, `fsspec`, `tempfile`, `numpy`, `pandas`, `dask`, `netCDF4`\n",
    "\n",
    "---\n",
    "\n",
    "##### Notes\n",
    "\n",
    "- Longitude in ERA5 is stored in **0–360** format — Minnesota spans `265–273`\n",
    "- This script handles **forecast reset bugs** by applying discrete hourly transformation logic if extended\n",
    "- All temporary NetCDFs are deleted at the end of execution to manage disk space\n",
    "\n",
    "---\n",
    "\n",
    "*Use this script as a robust template for extracting and preprocessing other CMIP6 or NASA datasets by adjusting bounds, variables, and model paths.*\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35bbb7db-8b68-4115-add0-314842f58e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 1: Loading NASA NEX-GDDP Data from S3 ---\n",
      "\n",
      "Processing variable: hurs\n",
      "  - Successfully loaded hurs for 2015\n",
      "  - Successfully loaded hurs for 2016\n",
      "  - Successfully loaded hurs for 2017\n",
      "  - Successfully loaded hurs for 2018\n",
      "  - Successfully loaded hurs for 2019\n",
      "  - Successfully loaded hurs for 2020\n",
      "  --- Concatenated hurs for years 2015-2020 ---\n",
      "\n",
      "Processing variable: pr\n",
      "  - Successfully loaded pr for 2015\n",
      "  - Successfully loaded pr for 2016\n",
      "  - Successfully loaded pr for 2017\n",
      "  - Successfully loaded pr for 2018\n",
      "  - Successfully loaded pr for 2019\n",
      "  - Successfully loaded pr for 2020\n",
      "  --- Concatenated pr for years 2015-2020 ---\n",
      "\n",
      "Processing variable: rlds\n",
      "  - Successfully loaded rlds for 2015\n",
      "  - Successfully loaded rlds for 2016\n",
      "  - Successfully loaded rlds for 2017\n",
      "  - Successfully loaded rlds for 2018\n",
      "  - Successfully loaded rlds for 2019\n",
      "  - Successfully loaded rlds for 2020\n",
      "  --- Concatenated rlds for years 2015-2020 ---\n",
      "\n",
      "Processing variable: rsds\n",
      "  - Successfully loaded rsds for 2015\n",
      "  - Successfully loaded rsds for 2016\n",
      "  - Successfully loaded rsds for 2017\n",
      "  - Successfully loaded rsds for 2018\n",
      "  - Successfully loaded rsds for 2019\n",
      "  - Successfully loaded rsds for 2020\n",
      "  --- Concatenated rsds for years 2015-2020 ---\n",
      "\n",
      "Processing variable: sfcWind\n",
      "  - Successfully loaded sfcWind for 2015\n",
      "  - Successfully loaded sfcWind for 2016\n",
      "  - Successfully loaded sfcWind for 2017\n",
      "  - Successfully loaded sfcWind for 2018\n",
      "  - Successfully loaded sfcWind for 2019\n",
      "  - Successfully loaded sfcWind for 2020\n",
      "  --- Concatenated sfcWind for years 2015-2020 ---\n",
      "\n",
      "Processing variable: tas\n",
      "  - Successfully loaded tas for 2015\n",
      "  - Successfully loaded tas for 2016\n",
      "  - Successfully loaded tas for 2017\n",
      "  - Successfully loaded tas for 2018\n",
      "  - Successfully loaded tas for 2019\n",
      "  - Successfully loaded tas for 2020\n",
      "  --- Concatenated tas for years 2015-2020 ---\n",
      "\n",
      "Processing variable: tasmax\n",
      "  - Successfully loaded tasmax for 2015\n",
      "  - Successfully loaded tasmax for 2016\n",
      "  - Successfully loaded tasmax for 2017\n",
      "  - Successfully loaded tasmax for 2018\n",
      "  - Successfully loaded tasmax for 2019\n",
      "  - Successfully loaded tasmax for 2020\n",
      "  --- Concatenated tasmax for years 2015-2020 ---\n",
      "\n",
      "Processing variable: tasmin\n",
      "  - Successfully loaded tasmin for 2015\n",
      "  - Successfully loaded tasmin for 2016\n",
      "  - Successfully loaded tasmin for 2017\n",
      "  - Successfully loaded tasmin for 2018\n",
      "  - Successfully loaded tasmin for 2019\n",
      "  - Successfully loaded tasmin for 2020\n",
      "  --- Concatenated tasmin for years 2015-2020 ---\n",
      "\n",
      "--- Final Combined Xarray Dataset (All Variables, All Years) ---\n",
      "\n",
      "--- Step 2: Filtering for Minnesota and Converting to DataFrame ---\n",
      "\n",
      "--- Converting to Pandas DataFrame ---\n",
      "[########################################] | 100% Completed | 22.58 s\n",
      "[########################################] | 100% Completed | 20.35 s\n",
      "[########################################] | 100% Completed | 23.38 s\n",
      "[########################################] | 100% Completed | 22.28 s\n",
      "[########################################] | 100% Completed | 22.67 s\n",
      "[########################################] | 100% Completed | 21.36 s\n",
      "[########################################] | 100% Completed | 21.36 s\n",
      "[########################################] | 100% Completed | 22.69 s\n",
      "  Found duplicated coordinate columns: ['lat', 'lon']. Dropping them before resetting index.\n",
      "  Resetting index to convert coordinates to columns...\n",
      "\n",
      "--- Step 3: Standardizing Units for NASA Data ---\n",
      "  Unit standardization complete.\n",
      "\n",
      "--- Sample of Final NASA DataFrame ---\n",
      "                 time     lat      lon       hurs   pr        rlds  \\\n",
      "0 2015-01-01 12:00:00  43.625  265.125  71.094406  0.0  206.887085   \n",
      "1 2015-01-01 12:00:00  43.625  265.375  72.144753  0.0  205.703156   \n",
      "2 2015-01-01 12:00:00  43.625  265.625  73.190704  0.0  204.703918   \n",
      "3 2015-01-01 12:00:00  43.625  265.875  74.027748  0.0  204.430679   \n",
      "4 2015-01-01 12:00:00  43.625  266.125  74.487694  0.0  205.313217   \n",
      "\n",
      "         rsds   sfcWind         tas      tasmax      tasmin  precip_daily_mm  \n",
      "0  106.612808  1.424006  271.165405  275.921509  266.409302              0.0  \n",
      "1  106.595955  1.466005  271.278259  275.928833  266.627716              0.0  \n",
      "2  106.575455  1.510468  271.292480  275.862885  266.722076              0.0  \n",
      "3  106.409210  1.519741  271.378510  275.827820  266.929199              0.0  \n",
      "4  106.002380  1.468931  271.401917  275.627075  267.176758              0.0  \n",
      "\n",
      "Shape of final NASA DataFrame: (1543168, 12)\n",
      "\n",
      "--- Step 4: Saving final data to: C:\\Users\\91788\\Downloads\\ERA5 Data\\Extracted\\NASA_Standardized_Minnesota_2015-2020.csv ---\n",
      "Save complete.\n",
      "\n",
      "--- Cleaning up temporary files ---\n",
      "ERROR: Could not remove tmp_yt9gz75.nc: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\91788\\\\AppData\\\\Local\\\\Temp\\\\tmp_yt9gz75.nc'\n",
      "ERROR: Could not remove tmpgypfr3yd.nc: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\91788\\\\AppData\\\\Local\\\\Temp\\\\tmpgypfr3yd.nc'\n",
      "ERROR: Could not remove tmpf47pxvgi.nc: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\91788\\\\AppData\\\\Local\\\\Temp\\\\tmpf47pxvgi.nc'\n",
      "ERROR: Could not remove tmpx0rryaa0.nc: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\91788\\\\AppData\\\\Local\\\\Temp\\\\tmpx0rryaa0.nc'\n",
      "ERROR: Could not remove tmpwwd6m3b3.nc: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\91788\\\\AppData\\\\Local\\\\Temp\\\\tmpwwd6m3b3.nc'\n",
      "ERROR: Could not remove tmpc5x5s7ap.nc: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\91788\\\\AppData\\\\Local\\\\Temp\\\\tmpc5x5s7ap.nc'\n",
      "ERROR: Could not remove tmp32_7ii94.nc: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\91788\\\\AppData\\\\Local\\\\Temp\\\\tmp32_7ii94.nc'\n",
      "ERROR: Could not remove tmpr5p1fawy.nc: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\91788\\\\AppData\\\\Local\\\\Temp\\\\tmpr5p1fawy.nc'\n",
      "ERROR: Could not remove tmpu8ipzxdq.nc: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\91788\\\\AppData\\\\Local\\\\Temp\\\\tmpu8ipzxdq.nc'\n",
      "ERROR: Could not remove tmp1x4j4n9e.nc: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\91788\\\\AppData\\\\Local\\\\Temp\\\\tmp1x4j4n9e.nc'\n",
      "ERROR: Could not remove tmp75_4yica.nc: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\91788\\\\AppData\\\\Local\\\\Temp\\\\tmp75_4yica.nc'\n",
      "ERROR: Could not remove tmpr0q38q7s.nc: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\91788\\\\AppData\\\\Local\\\\Temp\\\\tmpr0q38q7s.nc'\n",
      "ERROR: Could not remove tmpe12sp1v_.nc: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\91788\\\\AppData\\\\Local\\\\Temp\\\\tmpe12sp1v_.nc'\n",
      "ERROR: Could not remove tmpe2y2mx8b.nc: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\91788\\\\AppData\\\\Local\\\\Temp\\\\tmpe2y2mx8b.nc'\n",
      "ERROR: Could not remove tmplbgnzrav.nc: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\91788\\\\AppData\\\\Local\\\\Temp\\\\tmplbgnzrav.nc'\n",
      "ERROR: Could not remove tmpuzwsapjn.nc: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\91788\\\\AppData\\\\Local\\\\Temp\\\\tmpuzwsapjn.nc'\n",
      "ERROR: Could not remove tmpj9bdswwc.nc: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\91788\\\\AppData\\\\Local\\\\Temp\\\\tmpj9bdswwc.nc'\n",
      "ERROR: Could not remove tmprb0ryx3s.nc: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\91788\\\\AppData\\\\Local\\\\Temp\\\\tmprb0ryx3s.nc'\n",
      "ERROR: Could not remove tmptp60ythr.nc: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\91788\\\\AppData\\\\Local\\\\Temp\\\\tmptp60ythr.nc'\n",
      "ERROR: Could not remove tmpljea2_vi.nc: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\91788\\\\AppData\\\\Local\\\\Temp\\\\tmpljea2_vi.nc'\n",
      "ERROR: Could not remove tmp5alf1b27.nc: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\91788\\\\AppData\\\\Local\\\\Temp\\\\tmp5alf1b27.nc'\n",
      "ERROR: Could not remove tmpeqeeowyt.nc: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\91788\\\\AppData\\\\Local\\\\Temp\\\\tmpeqeeowyt.nc'\n",
      "ERROR: Could not remove tmprhxm_y36.nc: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\91788\\\\AppData\\\\Local\\\\Temp\\\\tmprhxm_y36.nc'\n",
      "ERROR: Could not remove tmp9hgg0ov2.nc: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\91788\\\\AppData\\\\Local\\\\Temp\\\\tmp9hgg0ov2.nc'\n",
      "ERROR: Could not remove tmptw9ds9qi.nc: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\91788\\\\AppData\\\\Local\\\\Temp\\\\tmptw9ds9qi.nc'\n",
      "ERROR: Could not remove tmpz0vimdkf.nc: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\91788\\\\AppData\\\\Local\\\\Temp\\\\tmpz0vimdkf.nc'\n",
      "ERROR: Could not remove tmpk2bgeun0.nc: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\91788\\\\AppData\\\\Local\\\\Temp\\\\tmpk2bgeun0.nc'\n",
      "ERROR: Could not remove tmpn7vgzo37.nc: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\91788\\\\AppData\\\\Local\\\\Temp\\\\tmpn7vgzo37.nc'\n",
      "ERROR: Could not remove tmphe9x7ixp.nc: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\91788\\\\AppData\\\\Local\\\\Temp\\\\tmphe9x7ixp.nc'\n",
      "ERROR: Could not remove tmp74qsn8p6.nc: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\91788\\\\AppData\\\\Local\\\\Temp\\\\tmp74qsn8p6.nc'\n",
      "ERROR: Could not remove tmpeinox8lf.nc: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\91788\\\\AppData\\\\Local\\\\Temp\\\\tmpeinox8lf.nc'\n",
      "ERROR: Could not remove tmpoehufaas.nc: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\91788\\\\AppData\\\\Local\\\\Temp\\\\tmpoehufaas.nc'\n",
      "ERROR: Could not remove tmpqeuhx4m6.nc: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\91788\\\\AppData\\\\Local\\\\Temp\\\\tmpqeuhx4m6.nc'\n",
      "ERROR: Could not remove tmpmlqb2pi5.nc: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\91788\\\\AppData\\\\Local\\\\Temp\\\\tmpmlqb2pi5.nc'\n",
      "ERROR: Could not remove tmph4kldxle.nc: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\91788\\\\AppData\\\\Local\\\\Temp\\\\tmph4kldxle.nc'\n",
      "ERROR: Could not remove tmpq3n56723.nc: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\91788\\\\AppData\\\\Local\\\\Temp\\\\tmpq3n56723.nc'\n",
      "ERROR: Could not remove tmp9htk0xir.nc: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\91788\\\\AppData\\\\Local\\\\Temp\\\\tmp9htk0xir.nc'\n",
      "ERROR: Could not remove tmpy15myatp.nc: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\91788\\\\AppData\\\\Local\\\\Temp\\\\tmpy15myatp.nc'\n",
      "ERROR: Could not remove tmpomdq8uc0.nc: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\91788\\\\AppData\\\\Local\\\\Temp\\\\tmpomdq8uc0.nc'\n",
      "ERROR: Could not remove tmpbmik7ckl.nc: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\91788\\\\AppData\\\\Local\\\\Temp\\\\tmpbmik7ckl.nc'\n",
      "ERROR: Could not remove tmptgib5now.nc: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\91788\\\\AppData\\\\Local\\\\Temp\\\\tmptgib5now.nc'\n",
      "ERROR: Could not remove tmpqm8fp6vm.nc: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\91788\\\\AppData\\\\Local\\\\Temp\\\\tmpqm8fp6vm.nc'\n",
      "ERROR: Could not remove tmpkl9og38_.nc: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\91788\\\\AppData\\\\Local\\\\Temp\\\\tmpkl9og38_.nc'\n",
      "ERROR: Could not remove tmpme6rcstp.nc: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\91788\\\\AppData\\\\Local\\\\Temp\\\\tmpme6rcstp.nc'\n",
      "ERROR: Could not remove tmpu9m7dajz.nc: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\91788\\\\AppData\\\\Local\\\\Temp\\\\tmpu9m7dajz.nc'\n",
      "ERROR: Could not remove tmp8oqxebf6.nc: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\91788\\\\AppData\\\\Local\\\\Temp\\\\tmp8oqxebf6.nc'\n",
      "ERROR: Could not remove tmpk_k1gzfy.nc: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\91788\\\\AppData\\\\Local\\\\Temp\\\\tmpk_k1gzfy.nc'\n",
      "ERROR: Could not remove tmpd8t0awyz.nc: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\91788\\\\AppData\\\\Local\\\\Temp\\\\tmpd8t0awyz.nc'\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import fsspec\n",
    "import tempfile\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dask.diagnostics import ProgressBar\n",
    "import gc\n",
    "import time\n",
    "\n",
    "# --- 1. CONFIGURATION ---\n",
    "# Define the bounding box for the state of Minnesota\n",
    "MINNESOTA_BOUNDS = {\n",
    "    \"min_lat\": 43.5,\n",
    "    \"max_lat\": 49.0,\n",
    "    \"min_lon\": 265.0, # Using 0-360 longitude format as in the source files\n",
    "    \"max_lon\": 273.0\n",
    "}\n",
    "\n",
    "# Define the years we want to fetch and process for this run\n",
    "SELECTED_YEARS = ['2015', '2016', '2017', '2018', '2019', '2020']\n",
    "#['2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014']\n",
    "\n",
    "# Define the variables required for our downscaling models\n",
    "VARIABLES_TO_FETCH = [\n",
    "    'hurs', 'pr', 'rlds', 'rsds', 'sfcWind', 'tas', 'tasmax', 'tasmin'\n",
    "]\n",
    "\n",
    "# --- CORRECTED CONFIGURATION ---\n",
    "# Define the S3 path and scenario name\n",
    "SCENARIO = 'ssp126' # Changed from 'ssp126' # historical/r1i1p1f2: 2000-2014 , ssp126/r1i1p1f2: 2015 onwards\n",
    "BASE_S3_PREFIX = f's3://nex-gddp-cmip6/NEX-GDDP-CMIP6/CNRM-CM6-1/{SCENARIO}/r1i1p1f2/'\n",
    "\n",
    "# List to keep track of temporary files for cleanup\n",
    "all_temp_files = []\n",
    "\n",
    "# --- 2. DATA FETCHING AND PROCESSING ---\n",
    "\n",
    "def download_and_open_netcdf(s3_path, var_name, year):\n",
    "    \"\"\"Downloads a NetCDF file from S3 to a temporary local file and opens it with xarray.\"\"\"\n",
    "    try:\n",
    "        with fsspec.open(s3_path, mode='rb', anon=True) as remote_file:\n",
    "            # Create a temporary file to store the downloaded data\n",
    "            fd, tmp_path = tempfile.mkstemp(suffix=\".nc\")\n",
    "            with os.fdopen(fd, 'wb') as tmp_file:\n",
    "                tmp_file.write(remote_file.read())\n",
    "            all_temp_files.append(tmp_path)\n",
    "            \n",
    "            # Open the local temporary file with xarray\n",
    "            ds = xr.open_dataset(tmp_path, engine='netcdf4', chunks='auto')\n",
    "            print(f\"  - Successfully loaded {var_name} for {year}\")\n",
    "            return ds\n",
    "    except FileNotFoundError:\n",
    "        print(f\"  - ERROR: File not found for {var_name} in {year} at {s3_path}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"  - ERROR processing {var_name} for {year}: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- Main Script Execution ---\n",
    "print(\"--- Step 1: Loading NASA NEX-GDDP Data from S3 ---\")\n",
    "\n",
    "all_variable_datasets = []\n",
    "for var_name in VARIABLES_TO_FETCH:\n",
    "    print(f\"\\nProcessing variable: {var_name}\")\n",
    "    datasets_for_current_var = []\n",
    "    for year in SELECTED_YEARS:\n",
    "        # --- CORRECTED S3 PATH CONSTRUCTION ---\n",
    "        s3_path = f\"{BASE_S3_PREFIX}{var_name}/{var_name}_day_CNRM-CM6-1_{SCENARIO}_r1i1p1f2_gr_{year}.nc\"\n",
    "        ds = download_and_open_netcdf(s3_path, var_name, year)\n",
    "        if ds is not None:\n",
    "            datasets_for_current_var.append(ds)\n",
    "            \n",
    "    if datasets_for_current_var:\n",
    "        # Concatenate the yearly datasets for the current variable\n",
    "        with ProgressBar():\n",
    "            concatenated_var_ds = xr.concat(datasets_for_current_var, dim='time')\n",
    "        all_variable_datasets.append(concatenated_var_ds)\n",
    "        print(f\"  --- Concatenated {var_name} for years {min(SELECTED_YEARS)}-{max(SELECTED_YEARS)} ---\")\n",
    "\n",
    "# Merge all variables into a single xarray Dataset\n",
    "if all_variable_datasets:\n",
    "    with ProgressBar():\n",
    "        final_combined_ds = xr.merge(all_variable_datasets)\n",
    "    print(\"\\n--- Final Combined Xarray Dataset (All Variables, All Years) ---\")\n",
    "else:\n",
    "    print(\"No datasets were successfully combined. Exiting.\")\n",
    "    exit()\n",
    "\n",
    "# --- Step 2: Filtering and Converting to DataFrame ---\n",
    "print(\"\\n--- Step 2: Filtering for Minnesota and Converting to DataFrame ---\")\n",
    "\n",
    "# Create a boolean mask for the Minnesota bounding box\n",
    "lat_mask = (final_combined_ds.lat >= MINNESOTA_BOUNDS[\"min_lat\"]) & (final_combined_ds.lat <= MINNESOTA_BOUNDS[\"max_lat\"])\n",
    "lon_mask = (final_combined_ds.lon >= MINNESOTA_BOUNDS[\"min_lon\"]) & (final_combined_ds.lon <= MINNESOTA_BOUNDS[\"max_lon\"])\n",
    "\n",
    "# Apply the spatial filter\n",
    "with ProgressBar():\n",
    "    filtered_ds = final_combined_ds.where(lat_mask & lon_mask, drop=True)\n",
    "\n",
    "print(\"\\n--- Converting to Pandas DataFrame ---\")\n",
    "# Stack spatial dimensions and convert to a pandas DataFrame\n",
    "with ProgressBar():\n",
    "    stacked_ds = filtered_ds.stack(spatial_point=('lat', 'lon'))\n",
    "    nasa_df = stacked_ds.to_dataframe()\n",
    "\n",
    "# --- THE FIX: Robustly handle the index before resetting ---\n",
    "# Check if 'lat' or 'lon' accidentally ended up as columns and drop them.\n",
    "cols_to_drop = [col for col in ['lat', 'lon'] if col in nasa_df.columns]\n",
    "if cols_to_drop:\n",
    "    print(f\"  Found duplicated coordinate columns: {cols_to_drop}. Dropping them before resetting index.\")\n",
    "    nasa_df = nasa_df.drop(columns=cols_to_drop)\n",
    "\n",
    "# Now, resetting the index will work reliably.\n",
    "print(\"  Resetting index to convert coordinates to columns...\")\n",
    "nasa_df = nasa_df.reset_index()\n",
    "\n",
    "# Clean up any rows that might be all null after filtering\n",
    "nasa_df = nasa_df.dropna(subset=VARIABLES_TO_FETCH, how='all')\n",
    "\n",
    "print(\"\\n--- Step 3: Standardizing Units for NASA Data ---\")\n",
    "# Apply the necessary unit conversions\n",
    "nasa_df['precip_daily_mm'] = nasa_df['pr'] * 86400\n",
    "# Other variables are already in standard units (K, m/s, %, W/m^2)\n",
    "\n",
    "print(\"  Unit standardization complete.\")\n",
    "print(\"\\n--- Sample of Final NASA DataFrame ---\")\n",
    "print(nasa_df.head())\n",
    "print(f\"\\nShape of final NASA DataFrame: {nasa_df.shape}\")\n",
    "\n",
    "\n",
    "# --- Step 4: Save the Processed Data ---\n",
    "try:\n",
    "    ROOT_DATA_DIR = r\"C:\\Users\\91788\\Downloads\\ERA5 Data\\Extracted\"\n",
    "    os.makedirs(ROOT_DATA_DIR, exist_ok=True)\n",
    "    output_filename = f\"NASA_Standardized_Minnesota_{min(SELECTED_YEARS)}-{max(SELECTED_YEARS)}.csv\"\n",
    "    output_path = os.path.join(ROOT_DATA_DIR, output_filename)\n",
    "    print(f\"\\n--- Step 4: Saving final data to: {output_path} ---\")\n",
    "    nasa_df.to_csv(output_path, index=False)\n",
    "    print(\"Save complete.\")\n",
    "except NameError:\n",
    "    print(\"\\nSkipping file save as ROOT_DATA_DIR is not defined.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn error occurred while saving the file: {e}\")\n",
    "\n",
    "\n",
    "# --- Cleanup ---\n",
    "print(\"\\n--- Cleaning up temporary files ---\")\n",
    "# Close xarray file handles\n",
    "if 'final_combined_ds' in locals(): final_combined_ds.close()\n",
    "if 'filtered_ds' in locals(): filtered_ds.close()\n",
    "if 'stacked_ds' in locals(): stacked_ds.close()\n",
    "gc.collect()\n",
    "time.sleep(1) # Give a moment for file handles to release\n",
    "\n",
    "for fp in all_temp_files:\n",
    "    if os.path.exists(fp):\n",
    "        try:\n",
    "            os.remove(fp)\n",
    "            # print(f\"Removed: {os.path.basename(fp)}\") # Optional: uncomment for verbose output\n",
    "        except Exception as e:\n",
    "            print(f\"ERROR: Could not remove {os.path.basename(fp)}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f779e790-c671-4dbc-b8c6-e4b39f440c28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
