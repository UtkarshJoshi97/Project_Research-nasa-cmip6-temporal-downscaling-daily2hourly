{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88677099-6a2e-43da-b128-565c601aa5e7",
   "metadata": {},
   "source": [
    "## Two-Stage Downscaling Approach\n",
    "\n",
    "### Downscaling Model Explanations by Variable\n",
    "\n",
    "A concise explanation of the statistical downscaling approach used for each key climate variable. For each variable, we train a profile of **24 independent linear regression models**, one for each **hour of the day**.\n",
    "\n",
    "---\n",
    "\n",
    "#### Temperature Profile (`air_temperature_k`)\n",
    "\n",
    "- **Approach:** Multivariate Linear Regression  \n",
    "- **Predictors (Inputs):**\n",
    "  - `tas` – daily mean temperature  \n",
    "  - `tasmin` – daily minimum temperature  \n",
    "  - `tasmax` – daily maximum temperature  \n",
    "\n",
    "- **Logic:**  \n",
    "  Each hourly model learns a unique equation based on these three inputs. For example:\n",
    "  - The **2:00 AM** model tends to give the highest weight to `tasmin`\n",
    "  - The **2:00 PM** model emphasizes `tasmax`\n",
    "\n",
    "  This allows the model to accurately reconstruct the **diurnal temperature curve** based on the day's specific characteristics.\n",
    "\n",
    "---\n",
    "\n",
    "#### Wind Profile (`wind_speed_ms`)\n",
    "\n",
    "- **Approach:** Two-Stage Multivariate Linear Regression  \n",
    "- **Challenge:** NASA data provides only one daily wind predictor (`sfcWind`), so we break it into two stages.\n",
    "\n",
    "##### Stage 1: Daily Characteristics Estimation\n",
    "Two simple models are trained on historical ERA5 data to infer additional daily characteristics:\n",
    "\n",
    "- `model_max_from_mean` → predicts `daily_max_wind`  \n",
    "- `model_std_from_mean` → predicts `daily_std_dev` (gustiness)\n",
    "\n",
    "##### Stage 2: Hourly Value Generation\n",
    "The 24 hourly models are then trained using:\n",
    "- `daily_mean` (original NASA value)  \n",
    "- `predicted_max` (from Stage 1)  \n",
    "- `predicted_std_dev` (from Stage 1)\n",
    "\n",
    "This produces more realistic wind profiles:\n",
    "- **Gusty days** → spiky, dynamic curves  \n",
    "- **Calm days** → flatter, smoother curves\n",
    "\n",
    "---\n",
    "\n",
    "####  Humidity,  Solar &  Thermal Radiation Profiles\n",
    "\n",
    "- **Approach:** Univariate Linear Regression  \n",
    "- **Predictor (Input):** Single daily mean value from NASA data  \n",
    "  - `hurs` for humidity  \n",
    "  - `rsds` for solar radiation  \n",
    "  - Similar single-variable inputs for other radiation variables\n",
    "\n",
    "- **Logic:**  \n",
    "  While simpler than the temperature or wind models, these still capture **diurnal shape** across 24 hours.\n",
    "\n",
    "  **Example (Humidity):**\n",
    "  - The **2:00 AM** model predicts values *higher than the daily mean*\n",
    "  - The **2:00 PM** model predicts values *lower than the daily mean*\n",
    "\n",
    "  This behavior mimics real-world daily humidity cycles.\n",
    "\n",
    "---\n",
    "\n",
    "####  Research Materials and Resources\n",
    "\n",
    "This approach applies widely accepted **statistical downscaling** and **weather generation** techniques.\n",
    "\n",
    "####  Key Academic Papers\n",
    "\n",
    "##### 1. On the relationship between daily mean and other statistics:\n",
    "- **Pryor, S. C., Barthelmie, R. J., & Kjellström, E. (2005)**  \n",
    "  *A method for statistical downscaling of daily wind speed data*.  \n",
    "  _Journal of Applied Meteorology, 44(12), 1871–1884_  \n",
    "  - **Relevance:** Foundational method for inferring wind variability from daily means.\n",
    "\n",
    "##### 2. On regression-based approaches for temporal downscaling:\n",
    "- **Gleason, K. L. (2007)**  \n",
    "  *A daily U.S. data set for meteorological and climatological applications*.  \n",
    "  _8th Conference on Applied Climatology, AMS_  \n",
    "  - **Relevance:** Validates use of regression to connect daily summaries to hourly values.\n",
    "\n",
    "##### 3. On weather generators and statistical models:\n",
    "- **Wilks, D. S., & Wilby, R. L. (1999)**  \n",
    "  *The weather generation game: a review of stochastic weather models*.  \n",
    "  _Progress in Physical Geography, 23(3), 329–357_  \n",
    "  - **Relevance:** Explains conditional generation of sub-daily data — similar in spirit to the two-stage wind model.\n",
    "\n",
    "---\n",
    "\n",
    "#### General Resources\n",
    "\n",
    "- **IPCC Data Distribution Centre**  \n",
    "  - Offers high-level guidelines on downscaling techniques and usage.\n",
    "- **IPCC Scenario Data Guidelines**  \n",
    "  - See sections on **statistical downscaling** for best practices.\n",
    "  - https://www.ipcc-data.org/guidelines/index.html\n",
    "\n",
    "---\n",
    "\n",
    "*This document is part of ongoing efforts to make climate projection data more granular, realistic, and usable in localized impact assessments and scenario modeling.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0f0dfc-2143-4b72-8548-625c642d956e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "044730fe-5a37-42df-8dce-79d10b730c9e",
   "metadata": {},
   "source": [
    "## Climate Downscaling Model Training & Temporal Validation (2000–2020)\n",
    "\n",
    "This script trains hourly downscaling models using daily climate statistics, then validates them on a held-out test period (2019–2020). It's built to handle multiple climate variables and captures diurnal variation through **24 separate hourly models per variable**.\n",
    "\n",
    "---\n",
    "\n",
    "#### 1. Configuration\n",
    "\n",
    "- **Input:** `MODELING_Train_2000-2020.csv` – Daily summary + hourly targets  \n",
    "- **Output Directory:** Trained models saved to `/trained_models_temporal_holdout/`  \n",
    "- **Validation Output:** Predictions saved to `TEMPORAL_VALIDATION_Predictions_2019-2020.csv`\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. Load & Split Data\n",
    "\n",
    "- Loads full 2000–2020 dataset\n",
    "- Splits into:\n",
    "  - **Training set:** 2000–2018  \n",
    "  - **Test set:** 2019–2020 (temporal holdout)\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. Model Training\n",
    "\n",
    "#### Wind Speed (Two-Stage)\n",
    "- **Stage 1:**  \n",
    "  Trains two regression models to predict:\n",
    "  - `wind_speed_ms_max`  \n",
    "  - `wind_speed_ms_std`  \n",
    "  from `wind_speed_ms_mean`\n",
    "\n",
    "- Saves these models for later use.\n",
    "\n",
    "#### Hourly Models (Per Variable)\n",
    "Trains **24 hourly Linear Regression models** for each variable:\n",
    "\n",
    "| Variable                   | Predictors |\n",
    "|----------------------------|------------|\n",
    "| `air_temperature_k`        | Mean, Min, Max |\n",
    "| `wind_speed_ms`            | Mean, Max, Std |\n",
    "| `relative_humidity_percent`| Mean |\n",
    "| `solar_radiation_w_m2`     | Mean |\n",
    "| `thermal_radiation_w_m2`   | Mean |\n",
    "| `precip_hourly_mm`         | Sum |\n",
    "\n",
    "All trained models are saved individually using `joblib`.\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. Prediction: Temporal Test Period (2019–2020)\n",
    "\n",
    "- Uses **actual daily stats** from the test set (no synthetic input).\n",
    "- For each variable:\n",
    "  - Predicts 24 hourly values using the trained models\n",
    "  - Reconstructs continuous hourly time series\n",
    "\n",
    "---\n",
    "\n",
    "#### 5. Validation\n",
    "\n",
    "- Actual and predicted hourly values are compared\n",
    "- Error metrics reported:\n",
    "  - **MAE** (Mean Absolute Error)\n",
    "  - **RMSE** (Root Mean Squared Error)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "###  6. Output\n",
    "\n",
    "- Saves merged prediction vs. actuals dataset as:\n",
    "TEMPORAL_VALIDATION_Predictions_2019-2020.csv\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "##### Tools Used\n",
    "\n",
    "- `pandas`, `numpy`, `sklearn`, `joblib`\n",
    "- Linear Regression for all modeling steps\n",
    "\n",
    "---\n",
    "\n",
    "*This pipeline enables accurate, high-resolution climate variable reconstruction by learning consistent relationships between daily summaries and hourly patterns.*  \n",
    "Perfect for building baseline models, downscaling ensembles, or running future scenario projections.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80bf49ee-daed-45d0-b578-90d888b5f7f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 1: Loading and splitting the master dataset ---\n",
      "  Successfully loaded master modeling data (2000-2020).\n",
      "  Training data shape (2000-2018): (6940, 88)\n",
      "  Validation data shape (2019-2020):  (731, 88)\n",
      "\n",
      "--- Step 2: Training all downscaling models on 2000-2018 data ---\n",
      "  Training wind characteristic models...\n",
      "  Saving Stage-1 wind models...\n",
      "  Training 24 hourly models for: air_temperature_k...\n",
      "  Training 24 hourly models for: wind_speed_ms...\n",
      "  Training 24 hourly models for: relative_humidity_percent...\n",
      "  Training 24 hourly models for: solar_radiation_w_m2...\n",
      "  Training 24 hourly models for: thermal_radiation_w_m2...\n",
      "  Training 24 hourly models for: precip_hourly_mm...\n",
      "--- All models have been trained successfully. ---\n",
      "\n",
      "--- Step 3: Generating hourly predictions for the test period (2019-2020) ---\n",
      "  Predicting hourly values for: air_temperature_k...\n",
      "  Predicting hourly values for: wind_speed_ms...\n",
      "  Predicting hourly values for: relative_humidity_percent...\n",
      "  Predicting hourly values for: solar_radiation_w_m2...\n",
      "  Predicting hourly values for: thermal_radiation_w_m2...\n",
      "  Predicting hourly values for: precip_hourly_mm...\n",
      "--- Hourly predictions generated successfully. ---\n",
      "\n",
      "--- Step 4: Validating predictions against actual 2019-2020 data ---\n",
      "  Temporal Hold-Out Test Results (2019-2020):\n",
      "    - air_temperature_k:\n",
      "        Mean Absolute Error (MAE):  1.2214\n",
      "        Root Mean Squared Error (RMSE): 1.8115\n",
      "    - wind_speed_ms:\n",
      "        Mean Absolute Error (MAE):  0.7210\n",
      "        Root Mean Squared Error (RMSE): 0.9442\n",
      "    - relative_humidity_percent:\n",
      "        Mean Absolute Error (MAE):  6.0383\n",
      "        Root Mean Squared Error (RMSE): 7.8900\n",
      "    - solar_radiation_w_m2:\n",
      "        Mean Absolute Error (MAE):  0.0001\n",
      "        Root Mean Squared Error (RMSE): 0.0006\n",
      "    - thermal_radiation_w_m2:\n",
      "        Mean Absolute Error (MAE):  0.0039\n",
      "        Root Mean Squared Error (RMSE): 0.0050\n",
      "    - precip_hourly_mm:\n",
      "        Mean Absolute Error (MAE):  0.1266\n",
      "        Root Mean Squared Error (RMSE): 0.4587\n",
      "\n",
      "--- Step 5: Saving final validation results to C:\\Users\\91788\\Downloads\\ERA5 Data\\Extracted\\TEMPORAL_VALIDATION_Predictions_2019-2020.csv ---\n",
      "Save complete.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import joblib\n",
    "\n",
    "# --- 1. CONFIGURATION ---\n",
    "# Define the location of your modeling-ready data file and where to save results.\n",
    "ROOT_DATA_DIR = r\"C:\\Users\\91788\\Downloads\\ERA5 Data\\Extracted\"\n",
    "MODELING_FILE_FULL = os.path.join(ROOT_DATA_DIR, \"MODELING_Train_2000-2020.csv\") # The master file\n",
    "MODEL_SAVE_DIR = os.path.join(ROOT_DATA_DIR, \"trained_models_temporal_holdout\")\n",
    "VALIDATION_OUTPUT_FILE = os.path.join(ROOT_DATA_DIR, \"TEMPORAL_VALIDATION_Predictions_2019-2020.csv\")\n",
    "\n",
    "os.makedirs(MODEL_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "# --- 2. LOAD AND SPLIT THE DATA ---\n",
    "print(\"--- Step 1: Loading and splitting the master dataset ---\")\n",
    "try:\n",
    "    master_df = pd.read_csv(MODELING_FILE_FULL, index_col=0, parse_dates=True)\n",
    "    print(\"  Successfully loaded master modeling data (2000-2020).\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: Could not find data file: {e.filename}.\")\n",
    "    exit()\n",
    "\n",
    "# Perform the temporal train/test split\n",
    "train_df = master_df[master_df.index.year <= 2018]\n",
    "test_df = master_df[master_df.index.year > 2018]\n",
    "\n",
    "print(f\"  Training data shape (2000-2018): {train_df.shape}\")\n",
    "print(f\"  Validation data shape (2019-2020):  {test_df.shape}\")\n",
    "\n",
    "\n",
    "# --- 3. TRAIN ALL MODELS (using 2000-2012 data) ---\n",
    "print(\"\\n--- Step 2: Training all downscaling models on 2000-2018 data ---\")\n",
    "trained_models = {}\n",
    "predictor_map = {\n",
    "    'air_temperature_k': ['air_temperature_k_mean', 'air_temperature_k_min', 'air_temperature_k_max'],\n",
    "    'wind_speed_ms': ['wind_speed_ms_mean', 'wind_speed_ms_max', 'wind_speed_ms_std'],\n",
    "    'relative_humidity_percent': ['relative_humidity_percent_mean'],\n",
    "    'solar_radiation_w_m2': ['solar_radiation_w_m2_mean'],\n",
    "    'thermal_radiation_w_m2': ['thermal_radiation_w_m2_mean'],\n",
    "    'precip_hourly_mm': ['precip_hourly_mm_sum']\n",
    "}\n",
    "\n",
    "# Train Stage-1 wind models\n",
    "print(\"  Training wind characteristic models...\")\n",
    "wind_predictors_train = train_df[['wind_speed_ms_mean']]\n",
    "model_wind_max = LinearRegression().fit(wind_predictors_train, train_df['wind_speed_ms_max'])\n",
    "model_wind_std = LinearRegression().fit(wind_predictors_train, train_df['wind_speed_ms_std'])\n",
    "\n",
    "# --- THE FIX: Explicitly save the Stage-1 wind models ---\n",
    "print(\"  Saving Stage-1 wind models...\")\n",
    "joblib.dump(model_wind_max, os.path.join(MODEL_SAVE_DIR, 'model_wind_max.pkl'))\n",
    "joblib.dump(model_wind_std, os.path.join(MODEL_SAVE_DIR, 'model_wind_std.pkl'))\n",
    "# We can add them to our dictionary for immediate use if needed\n",
    "trained_models['wind_max_from_mean'] = model_wind_max\n",
    "trained_models['wind_std_from_mean'] = model_wind_std\n",
    "\n",
    "\n",
    "# Train main hourly models\n",
    "for var_name, predictors in predictor_map.items():\n",
    "    print(f\"  Training 24 hourly models for: {var_name}...\")\n",
    "    trained_models[var_name] = {}\n",
    "    if not all(p in train_df.columns for p in predictors): continue\n",
    "    for hour in range(24):\n",
    "        target_col = f\"{var_name}_{hour}\"\n",
    "        if target_col not in train_df.columns: continue\n",
    "        model = LinearRegression().fit(train_df[predictors], train_df[target_col])\n",
    "        trained_models[var_name][hour] = model\n",
    "    # Save each variable's model dictionary\n",
    "    joblib.dump(trained_models[var_name], os.path.join(MODEL_SAVE_DIR, f'models_{var_name}.pkl'))\n",
    "\n",
    "print(\"--- All models have been trained successfully. ---\")\n",
    "\n",
    "\n",
    "# --- 4. MAKE PREDICTIONS ON THE TEMPORAL TEST SET (2013-2014) ---\n",
    "print(\"\\n--- Step 3: Generating hourly predictions for the test period (2019-2020) ---\")\n",
    "\n",
    "# For this ERA5-only validation, we use the actual daily stats from the test set.\n",
    "X_test_base = test_df.copy()\n",
    "\n",
    "final_predictions = {}\n",
    "for var_name, predictors in predictor_map.items():\n",
    "    if not all(p in X_test_base.columns for p in predictors): continue\n",
    "    \n",
    "    print(f\"  Predicting hourly values for: {var_name}...\")\n",
    "    hourly_preds_list = []\n",
    "    X_predict = X_test_base[predictors]\n",
    "    for hour in range(24):\n",
    "        model = trained_models[var_name].get(hour)\n",
    "        if model:\n",
    "            preds = model.predict(X_predict)\n",
    "            hourly_preds_list.append(pd.Series(preds, index=X_predict.index, name=hour))\n",
    "            \n",
    "    if hourly_preds_list:\n",
    "        var_df_wide = pd.concat(hourly_preds_list, axis=1)\n",
    "        var_stacked = var_df_wide.stack()\n",
    "        var_stacked.index = var_stacked.index.map(lambda x: x[0] + pd.to_timedelta(x[1], unit='h'))\n",
    "        final_predictions[f'predicted_{var_name}'] = var_stacked\n",
    "\n",
    "predictions_df = pd.DataFrame(final_predictions)\n",
    "print(\"--- Hourly predictions generated successfully. ---\")\n",
    "\n",
    "\n",
    "# --- 5. VALIDATE PREDICTIONS ---\n",
    "print(\"\\n--- Step 4: Validating predictions against actual 2019-2020 data ---\")\n",
    "\n",
    "# Re-structure the actual 2013-2014 data to be comparable\n",
    "actuals_df = pd.DataFrame()\n",
    "for var_name in predictor_map.keys():\n",
    "    actual_cols = [f\"{var_name}_{h}\" for h in range(24) if f\"{var_name}_{h}\" in test_df.columns]\n",
    "    if not actual_cols: continue\n",
    "    actual_hourly = test_df[actual_cols]\n",
    "    actual_hourly.columns = [int(c.split('_')[-1]) for c in actual_cols]\n",
    "    actual_stacked = actual_hourly.stack()\n",
    "    actual_stacked.index = actual_stacked.index.map(lambda x: x[0] + pd.to_timedelta(x[1], unit='h'))\n",
    "    actuals_df[f'actual_{var_name}'] = actual_stacked\n",
    "\n",
    "# Merge actuals and predictions\n",
    "validation_df = pd.merge(actuals_df, predictions_df, left_index=True, right_index=True, how=\"inner\")\n",
    "\n",
    "# Calculate and print final error metrics\n",
    "print(\"  Temporal Hold-Out Test Results (2019-2020):\")\n",
    "for var_name in predictor_map.keys():\n",
    "    actual_col, predicted_col = f'actual_{var_name}', f'predicted_{var_name}'\n",
    "    if actual_col in validation_df.columns and predicted_col in validation_df.columns:\n",
    "        temp_compare_df = validation_df[[actual_col, predicted_col]].dropna()\n",
    "        if not temp_compare_df.empty:\n",
    "            mae = mean_absolute_error(temp_compare_df[actual_col], temp_compare_df[predicted_col])\n",
    "            rmse = np.sqrt(mean_squared_error(temp_compare_df[actual_col], temp_compare_df[predicted_col]))\n",
    "            print(f\"    - {var_name}:\")\n",
    "            print(f\"        Mean Absolute Error (MAE):  {mae:.4f}\")\n",
    "            print(f\"        Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "\n",
    "# --- 6. SAVE FINAL RESULTS ---\n",
    "print(f\"\\n--- Step 5: Saving final validation results to {VALIDATION_OUTPUT_FILE} ---\")\n",
    "validation_df.to_csv(VALIDATION_OUTPUT_FILE)\n",
    "print(\"Save complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4902eed3-c03d-4cdd-bd82-652fab368570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading temporal validation data ---\n",
      "  Successfully loaded validation data.\n",
      "\n",
      "Generating plot for 'air_temperature_k' from 2019-07-01 to 2019-07-03 (Hourly)...\n",
      "  Plot saved to: C:\\Users\\91788\\Downloads\\ERA5 Data\\Extracted\\temporal_validation_plots\\Temporal_Validation_air_temperature_k_2019-07-01_to_2019-07-03_hourly.png\n",
      "\n",
      "Generating plot for 'air_temperature_k' from 2019-07-01 to 2019-07-31 (Hourly)...\n",
      "  Plot saved to: C:\\Users\\91788\\Downloads\\ERA5 Data\\Extracted\\temporal_validation_plots\\Temporal_Validation_air_temperature_k_2019-07-01_to_2019-07-31_hourly.png\n",
      "\n",
      "Generating plot for 'air_temperature_k' from 2019-01-01 to 2019-12-31 (D Resample)...\n",
      "  Plot saved to: C:\\Users\\91788\\Downloads\\ERA5 Data\\Extracted\\temporal_validation_plots\\Temporal_Validation_air_temperature_k_2019-01-01_to_2019-12-31_D.png\n",
      "\n",
      "Generating plot for 'wind_speed_ms' from 2019-07-01 to 2019-07-03 (Hourly)...\n",
      "  Plot saved to: C:\\Users\\91788\\Downloads\\ERA5 Data\\Extracted\\temporal_validation_plots\\Temporal_Validation_wind_speed_ms_2019-07-01_to_2019-07-03_hourly.png\n",
      "\n",
      "Generating plot for 'wind_speed_ms' from 2019-07-01 to 2019-07-31 (Hourly)...\n",
      "  Plot saved to: C:\\Users\\91788\\Downloads\\ERA5 Data\\Extracted\\temporal_validation_plots\\Temporal_Validation_wind_speed_ms_2019-07-01_to_2019-07-31_hourly.png\n",
      "\n",
      "Generating plot for 'wind_speed_ms' from 2019-01-01 to 2019-12-31 (D Resample)...\n",
      "  Plot saved to: C:\\Users\\91788\\Downloads\\ERA5 Data\\Extracted\\temporal_validation_plots\\Temporal_Validation_wind_speed_ms_2019-01-01_to_2019-12-31_D.png\n",
      "\n",
      "Generating plot for 'relative_humidity_percent' from 2019-07-01 to 2019-07-03 (Hourly)...\n",
      "  Plot saved to: C:\\Users\\91788\\Downloads\\ERA5 Data\\Extracted\\temporal_validation_plots\\Temporal_Validation_relative_humidity_percent_2019-07-01_to_2019-07-03_hourly.png\n",
      "\n",
      "Generating plot for 'relative_humidity_percent' from 2019-07-01 to 2019-07-31 (Hourly)...\n",
      "  Plot saved to: C:\\Users\\91788\\Downloads\\ERA5 Data\\Extracted\\temporal_validation_plots\\Temporal_Validation_relative_humidity_percent_2019-07-01_to_2019-07-31_hourly.png\n",
      "\n",
      "Generating plot for 'relative_humidity_percent' from 2019-01-01 to 2019-12-31 (D Resample)...\n",
      "  Plot saved to: C:\\Users\\91788\\Downloads\\ERA5 Data\\Extracted\\temporal_validation_plots\\Temporal_Validation_relative_humidity_percent_2019-01-01_to_2019-12-31_D.png\n",
      "\n",
      "Generating plot for 'precip_hourly_mm' from 2019-07-01 to 2019-07-03 (Hourly)...\n",
      "  Plot saved to: C:\\Users\\91788\\Downloads\\ERA5 Data\\Extracted\\temporal_validation_plots\\Temporal_Validation_precip_hourly_mm_2019-07-01_to_2019-07-03_hourly.png\n",
      "\n",
      "Generating plot for 'precip_hourly_mm' from 2019-07-01 to 2019-07-31 (Hourly)...\n",
      "  Plot saved to: C:\\Users\\91788\\Downloads\\ERA5 Data\\Extracted\\temporal_validation_plots\\Temporal_Validation_precip_hourly_mm_2019-07-01_to_2019-07-31_hourly.png\n",
      "\n",
      "Generating plot for 'precip_hourly_mm' from 2019-01-01 to 2019-12-31 (D Resample)...\n",
      "  Plot saved to: C:\\Users\\91788\\Downloads\\ERA5 Data\\Extracted\\temporal_validation_plots\\Temporal_Validation_precip_hourly_mm_2019-01-01_to_2019-12-31_D.png\n",
      "\n",
      "Generating plot for 'solar_radiation_w_m2' from 2019-07-01 to 2019-07-03 (Hourly)...\n",
      "  Plot saved to: C:\\Users\\91788\\Downloads\\ERA5 Data\\Extracted\\temporal_validation_plots\\Temporal_Validation_solar_radiation_w_m2_2019-07-01_to_2019-07-03_hourly.png\n",
      "\n",
      "Generating plot for 'solar_radiation_w_m2' from 2019-07-01 to 2019-07-31 (Hourly)...\n",
      "  Plot saved to: C:\\Users\\91788\\Downloads\\ERA5 Data\\Extracted\\temporal_validation_plots\\Temporal_Validation_solar_radiation_w_m2_2019-07-01_to_2019-07-31_hourly.png\n",
      "\n",
      "Generating plot for 'solar_radiation_w_m2' from 2019-01-01 to 2019-12-31 (D Resample)...\n",
      "  Plot saved to: C:\\Users\\91788\\Downloads\\ERA5 Data\\Extracted\\temporal_validation_plots\\Temporal_Validation_solar_radiation_w_m2_2019-01-01_to_2019-12-31_D.png\n",
      "\n",
      "Generating plot for 'thermal_radiation_w_m2' from 2019-07-01 to 2019-07-03 (Hourly)...\n",
      "  Plot saved to: C:\\Users\\91788\\Downloads\\ERA5 Data\\Extracted\\temporal_validation_plots\\Temporal_Validation_thermal_radiation_w_m2_2019-07-01_to_2019-07-03_hourly.png\n",
      "\n",
      "Generating plot for 'thermal_radiation_w_m2' from 2019-07-01 to 2019-07-31 (Hourly)...\n",
      "  Plot saved to: C:\\Users\\91788\\Downloads\\ERA5 Data\\Extracted\\temporal_validation_plots\\Temporal_Validation_thermal_radiation_w_m2_2019-07-01_to_2019-07-31_hourly.png\n",
      "\n",
      "Generating plot for 'thermal_radiation_w_m2' from 2019-01-01 to 2019-12-31 (D Resample)...\n",
      "  Plot saved to: C:\\Users\\91788\\Downloads\\ERA5 Data\\Extracted\\temporal_validation_plots\\Temporal_Validation_thermal_radiation_w_m2_2019-01-01_to_2019-12-31_D.png\n",
      "\n",
      "--- All plots generated successfully. ---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# --- 1. CONFIGURATION ---\n",
    "# Define the location of your validation file and where to save plots.\n",
    "ROOT_DATA_DIR = r\"C:\\Users\\91788\\Downloads\\ERA5 Data\\Extracted\"\n",
    "VALIDATION_FILE = os.path.join(ROOT_DATA_DIR, \"TEMPORAL_VALIDATION_Predictions_2019-2020.csv\")\n",
    "PLOT_SAVE_DIR = os.path.join(ROOT_DATA_DIR, \"temporal_validation_plots\")\n",
    "\n",
    "# Create a directory to save the plots\n",
    "os.makedirs(PLOT_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# --- 2. DATA LOADING ---\n",
    "print(\"--- Loading temporal validation data ---\")\n",
    "try:\n",
    "    # Use index_col=0 to specify the first column is the index.\n",
    "    validation_df = pd.read_csv(VALIDATION_FILE, index_col=0, parse_dates=True)\n",
    "    print(\"  Successfully loaded validation data.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Validation file not found at {VALIDATION_FILE}\")\n",
    "    exit()\n",
    "\n",
    "# --- 3. PLOTTING FUNCTION ---\n",
    "\n",
    "def plot_validation_timeseries(df, var_name, start_date, end_date, resample_freq=None):\n",
    "    \"\"\"\n",
    "    Creates and saves a time series plot comparing actual vs. predicted values\n",
    "    for a specific variable and date range. Can resample data for longer periods.\n",
    "    \"\"\"\n",
    "    actual_col = f'actual_{var_name}'\n",
    "    predicted_col = f'predicted_{var_name}'\n",
    "    \n",
    "    # Check if both required columns exist in the DataFrame\n",
    "    if not all(col in df.columns for col in [actual_col, predicted_col]):\n",
    "        print(f\"\\nSkipping plot for '{var_name}': one or both columns not found.\")\n",
    "        return\n",
    "\n",
    "    # Filter the DataFrame for the desired date range\n",
    "    plot_df = df.loc[start_date:end_date].copy()\n",
    "    \n",
    "    if plot_df.empty:\n",
    "        print(f\"\\nNo data found for '{var_name}' in the date range {start_date} to {end_date}.\")\n",
    "        return\n",
    "\n",
    "    # Optional: Resample data for longer time periods (e.g., daily mean for a yearly plot)\n",
    "    if resample_freq:\n",
    "        plot_df = plot_df[[actual_col, predicted_col]].resample(resample_freq).mean()\n",
    "        plot_title_suffix = f\"({resample_freq} Resample)\"\n",
    "    else:\n",
    "        plot_title_suffix = \"(Hourly)\"\n",
    "\n",
    "    print(f\"\\nGenerating plot for '{var_name}' from {start_date} to {end_date} {plot_title_suffix}...\")\n",
    "\n",
    "    # Create the plot\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    fig, ax = plt.subplots(figsize=(18, 8))\n",
    "    \n",
    "    # Plot the actual and predicted lines\n",
    "    ax.plot(plot_df.index, plot_df[actual_col], label='Actual (ERA5)', color='blue', linewidth=2.5, alpha=0.8)\n",
    "    ax.plot(plot_df.index, plot_df[predicted_col], label='Predicted (Model)', color='red', linewidth=1.5, linestyle='--')\n",
    "    \n",
    "    # Formatting the plot\n",
    "    plt.title(f'Temporal Validation: Actual vs. Predicted {var_name.replace(\"_\", \" \").title()}\\n({start_date} to {end_date}) {plot_title_suffix}', fontsize=18)\n",
    "    plt.ylabel(var_name.split('_')[-1].upper(), fontsize=14)\n",
    "    plt.xlabel('Date and Time', fontsize=14)\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.xticks(rotation=30, ha='right')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the plot to a file\n",
    "    plot_filename = f\"Temporal_Validation_{var_name}_{start_date}_to_{end_date}_{resample_freq or 'hourly'}.png\"\n",
    "    save_path = os.path.join(PLOT_SAVE_DIR, plot_filename)\n",
    "    plt.savefig(save_path, dpi=150)\n",
    "    print(f\"  Plot saved to: {save_path}\")\n",
    "    plt.close(fig) # Close the figure to free up memory\n",
    "\n",
    "\n",
    "# --- 4. EXECUTION ---\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    variables_to_plot = [\n",
    "        'air_temperature_k',\n",
    "        'wind_speed_ms',\n",
    "        'relative_humidity_percent',\n",
    "        'precip_hourly_mm',\n",
    "        'solar_radiation_w_m2',\n",
    "        'thermal_radiation_w_m2'\n",
    "    ]\n",
    "\n",
    "    for variable in variables_to_plot:\n",
    "        # Generate a 3-day plot (hourly resolution)\n",
    "        plot_validation_timeseries(validation_df, variable, '2019-07-01', '2019-07-03')\n",
    "        \n",
    "        # Generate a 1-month plot (hourly resolution)\n",
    "        plot_validation_timeseries(validation_df, variable, '2019-07-01', '2019-07-31')\n",
    "\n",
    "        # Generate a 1-year plot (resampled to daily mean for clarity)\n",
    "        plot_validation_timeseries(validation_df, variable, '2019-01-01', '2019-12-31', resample_freq='D')\n",
    "        \n",
    "    print(\"\\n--- All plots generated successfully. ---\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a5585e-5b97-4c15-88b0-29bc52d1e52a",
   "metadata": {},
   "source": [
    "## Final Validation: NASA-Based Downscaling vs. ERA5 Ground Truth (2021–2024)\n",
    "\n",
    "This script performs **final validation** of previously trained downscaling models using **daily NASA data (2021–2024)** to generate hourly predictions, which are then compared to **ERA5 hourly ground truth** data. The trained models were developed on historical data from 2000–2018.\n",
    "\n",
    "---\n",
    "\n",
    "#### Workflow Overview\n",
    "\n",
    "##### 1. **Configuration**\n",
    "\n",
    "- **Input:**\n",
    "  - NASA Daily Data → `NASA_Standardized_Minnesota_2021-2024.csv`\n",
    "  - ERA5 Hourly Ground Truth → `ERA5_Test_2021-2024.csv`\n",
    "- **Models:** Loaded from `/trained_models_temporal_holdout/`  \n",
    "- **Output:** Final validation file → `FINAL_VALIDATION_NASA_vs_ERA5_2021-2024.csv`\n",
    "\n",
    "---\n",
    "\n",
    "##### 2. **Data & Model Loading**\n",
    "\n",
    "- Loads daily NASA inputs and hourly ERA5 truth values\n",
    "- Loads trained Linear Regression models (one per hour per variable)\n",
    "- Applies two-stage wind models:\n",
    "  - `wind_speed_ms_max` and `wind_speed_ms_std` predicted from `wind_speed_ms_mean`\n",
    "\n",
    "---\n",
    "\n",
    "##### 3. **Generate Hourly Predictions**\n",
    "\n",
    "- Using daily predictors, the script reconstructs 24 hourly values for each variable\n",
    "- Predictions are made for:\n",
    "  - `air_temperature_k`\n",
    "  - `wind_speed_ms`\n",
    "  - `relative_humidity_percent`\n",
    "- Radiation and precipitation variables are **excluded** from this final run (due to low performance in earlier stages)\n",
    "\n",
    "---\n",
    "\n",
    "##### 4. **Validation: NASA Predictions vs. ERA5**\n",
    "\n",
    "- Merges predicted values with ERA5 hourly data\n",
    "- Computes key error metrics:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1916584e-857c-45d7-90b2-96d49fd17ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 1: Loading data and trained models for FINAL validation ---\n",
      "  Successfully loaded NASA daily data (2021-2024) with 1028544 total records.\n",
      "\n",
      "--- Filtering for Minneapolis Grid (Lat: 45.125, Lon: 266.625) ---\n",
      "  Filtering complete. Found 1461 records for the Minneapolis grid.\n",
      "  Successfully loaded ERA5 hourly ground truth data (2021-2024).\n",
      "  Loading pre-trained models (trained on 2000-2018)...\n",
      "  All models loaded successfully.\n",
      "\n",
      "--- Step 2: Preparing NASA data for prediction ---\n",
      "  Applying Stage-1 models to generate wind characteristics...\n",
      "  NASA predictor data prepared.\n",
      "\n",
      "--- Step 3: Generating hourly predictions from NASA daily data ---\n",
      "  Predicting hourly values for: air_temperature_k...\n",
      "  Predicting hourly values for: wind_speed_ms...\n",
      "  Predicting hourly values for: relative_humidity_percent...\n",
      "--- Hourly predictions generated successfully. ---\n",
      "\n",
      "--- Step 4: Validating predictions against ERA5 ground truth ---\n",
      "  Final Validation Results (NASA-based Predictions vs. ERA5 Actuals for 2021-2024):\n",
      "    - air_temperature_k:\n",
      "        Mean Absolute Error (MAE):    7.7238\n",
      "        Root Mean Squared Error (RMSE): 9.5949\n",
      "        R-squared (R²):               0.4148\n",
      "    - wind_speed_ms:\n",
      "        Mean Absolute Error (MAE):    1.6807\n",
      "        Root Mean Squared Error (RMSE): 2.1469\n",
      "        R-squared (R²):               -1.2222\n",
      "    - relative_humidity_percent:\n",
      "        Mean Absolute Error (MAE):    21.1248\n",
      "        Root Mean Squared Error (RMSE): 26.3464\n",
      "        R-squared (R²):               -3.2738\n",
      "\n",
      "--- Step 5: Saving final validation results to C:\\Users\\91788\\Downloads\\ERA5 Data\\Extracted\\FINAL_VALIDATION_NASA_vs_ERA5_2021-2024.csv ---\n",
      "Save complete.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import joblib\n",
    "\n",
    "# --- 1. CONFIGURATION ---\n",
    "# Define the paths for your prepared data files and saved models.\n",
    "ROOT_DATA_DIR = r\"C:\\Users\\91788\\Downloads\\ERA5 Data\\Extracted\"\n",
    "# Use the models trained on the older climate data (2000-2018)\n",
    "MODEL_SAVE_DIR = os.path.join(ROOT_DATA_DIR, \"trained_models_temporal_holdout\")\n",
    "\n",
    "# Input files for this final validation run\n",
    "# Assumes this CSV contains data for multiple grid points including lat/lon columns\n",
    "NASA_DAILY_INPUT_FILE = os.path.join(ROOT_DATA_DIR, \"NASA_Standardized_Minnesota_2021-2024.csv\")\n",
    "ERA5_HOURLY_GROUND_TRUTH_FILE = os.path.join(ROOT_DATA_DIR, \"ERA5_Test_2021-2024.csv\")\n",
    "\n",
    "# Output file for the final validation results\n",
    "FINAL_VALIDATION_OUTPUT_FILE = os.path.join(ROOT_DATA_DIR, \"FINAL_VALIDATION_NASA_vs_ERA5_2021-2024.csv\")\n",
    "\n",
    "# --- NEW: Grid Point Configuration ---\n",
    "# Define the specific NASA grid point for Minneapolis to filter for.\n",
    "# Using the coordinates confirmed as correct for the NASA grid.\n",
    "TARGET_LAT = 45.125\n",
    "TARGET_LON = 266.625\n",
    "\n",
    "\n",
    "# --- 2. LOAD DATA AND TRAINED MODELS ---\n",
    "print(\"--- Step 1: Loading data and trained models for FINAL validation ---\")\n",
    "\n",
    "# Load the multi-point, daily NASA data\n",
    "try:\n",
    "    # Important: We do not set index_col here yet, so we can filter by lat/lon first\n",
    "    nasa_df_full = pd.read_csv(NASA_DAILY_INPUT_FILE, parse_dates=['time'])\n",
    "    print(f\"  Successfully loaded NASA daily data (2021-2024) with {len(nasa_df_full)} total records.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: NASA data file not found at {NASA_DAILY_INPUT_FILE}.\")\n",
    "    exit()\n",
    "\n",
    "# --- NEW: Filtering for the Minneapolis Grid ---\n",
    "print(f\"\\n--- Filtering for Minneapolis Grid (Lat: {TARGET_LAT}, Lon: {TARGET_LON}) ---\")\n",
    "nasa_df = nasa_df_full[\n",
    "    (nasa_df_full['lat'] == TARGET_LAT) & (nasa_df_full['lon'] == TARGET_LON)\n",
    "].copy() # Use .copy() to avoid SettingWithCopyWarning\n",
    "\n",
    "if nasa_df.empty:\n",
    "    print(f\"Error: No data found for the specified grid point. Please check your input file and coordinates.\")\n",
    "    exit()\n",
    "\n",
    "# Set 'time' as the index now that filtering is complete\n",
    "nasa_df.set_index('time', inplace=True)\n",
    "print(f\"  Filtering complete. Found {len(nasa_df)} records for the Minneapolis grid.\")\n",
    "# --- End of New Section ---\n",
    "\n",
    "\n",
    "# Load the single-point, hourly ERA5 data (our ground truth)\n",
    "try:\n",
    "    era5_df = pd.read_csv(ERA5_HOURLY_GROUND_TRUTH_FILE, index_col='time', parse_dates=True)\n",
    "    print(\"  Successfully loaded ERA5 hourly ground truth data (2021-2024).\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: ERA5 ground truth file not found at {ERA5_HOURLY_GROUND_TRUTH_FILE}.\")\n",
    "    exit()\n",
    "\n",
    "# Load the library of trained models\n",
    "try:\n",
    "    print(\"  Loading pre-trained models (trained on 2000-2018)...\")\n",
    "    # This map uses the exact feature names the models were trained on\n",
    "    predictor_map = {\n",
    "        'air_temperature_k': ['air_temperature_k_mean', 'air_temperature_k_min', 'air_temperature_k_max'],\n",
    "        'wind_speed_ms': ['wind_speed_ms_mean', 'wind_speed_ms_max', 'wind_speed_ms_std'],\n",
    "        'relative_humidity_percent': ['relative_humidity_percent_mean']\n",
    "        # We exclude radiation/precip models as the simple linear approach was ineffective\n",
    "    }\n",
    "    trained_models = {}\n",
    "    for var_name in predictor_map.keys():\n",
    "        model_path = os.path.join(MODEL_SAVE_DIR, f'models_{var_name}.pkl')\n",
    "        trained_models[var_name] = joblib.load(model_path)\n",
    "    \n",
    "    trained_models['wind_max_from_mean'] = joblib.load(os.path.join(MODEL_SAVE_DIR, 'model_wind_max.pkl'))\n",
    "    trained_models['wind_std_from_mean'] = joblib.load(os.path.join(MODEL_SAVE_DIR, 'model_wind_std.pkl'))\n",
    "    print(\"  All models loaded successfully.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading model file: {e.filename}. Please ensure training was successful.\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "# --- 3. PREPARE NASA DATA FOR PREDICTION ---\n",
    "print(\"\\n--- Step 2: Preparing NASA data for prediction ---\")\n",
    "\n",
    "# Create the predictor DataFrame by renaming the NASA columns to match the training columns.\n",
    "nasa_predictors_df = nasa_df.rename(columns={\n",
    "    'tas': 'air_temperature_k_mean',\n",
    "    'tasmin': 'air_temperature_k_min',\n",
    "    'tasmax': 'air_temperature_k_max',\n",
    "    'sfcWind': 'wind_speed_ms_mean',\n",
    "    'hurs': 'relative_humidity_percent_mean'\n",
    "})\n",
    "\n",
    "# Apply two-stage model to generate wind characteristics\n",
    "print(\"  Applying Stage-1 models to generate wind characteristics...\")\n",
    "X_wind_mean = nasa_predictors_df[['wind_speed_ms_mean']]\n",
    "nasa_predictors_df['wind_speed_ms_max'] = trained_models['wind_max_from_mean'].predict(X_wind_mean)\n",
    "nasa_predictors_df['wind_speed_ms_std'] = trained_models['wind_std_from_mean'].predict(X_wind_mean)\n",
    "print(\"  NASA predictor data prepared.\")\n",
    "\n",
    "\n",
    "# --- 4. GENERATE HOURLY PREDICTIONS ---\n",
    "print(\"\\n--- Step 3: Generating hourly predictions from NASA daily data ---\")\n",
    "final_predictions = {}\n",
    "for var_name, predictors in predictor_map.items():\n",
    "    if not all(p in nasa_predictors_df.columns for p in predictors): continue\n",
    "    \n",
    "    print(f\"  Predicting hourly values for: {var_name}...\")\n",
    "    hourly_preds_list = []\n",
    "    X_predict = nasa_predictors_df[predictors]\n",
    "    for hour in range(24):\n",
    "        model = trained_models[var_name].get(hour)\n",
    "        if model:\n",
    "            preds = model.predict(X_predict)\n",
    "            hourly_preds_list.append(pd.Series(preds, index=X_predict.index, name=hour))\n",
    "    if hourly_preds_list:\n",
    "        var_df_wide = pd.concat(hourly_preds_list, axis=1)\n",
    "        var_stacked = var_df_wide.stack()\n",
    "        var_stacked.index = var_stacked.index.map(lambda x: x[0] + pd.to_timedelta(x[1], unit='h'))\n",
    "        final_predictions[f'predicted_{var_name}'] = var_stacked\n",
    "\n",
    "predictions_df = pd.DataFrame(final_predictions)\n",
    "print(\"--- Hourly predictions generated successfully. ---\")\n",
    "\n",
    "\n",
    "# --- 5. VALIDATE PREDICTIONS AND SAVE ---\n",
    "print(\"\\n--- Step 4: Validating predictions against ERA5 ground truth ---\")\n",
    "# Merge predictions with the actual hourly ERA5 data\n",
    "validation_df = pd.merge(\n",
    "    era5_df.rename(columns=lambda c: f\"actual_{c}\"),\n",
    "    predictions_df,\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "# Calculate and print final error metrics\n",
    "print(\"  Final Validation Results (NASA-based Predictions vs. ERA5 Actuals for 2021-2024):\")\n",
    "for var_name in predictor_map.keys():\n",
    "    actual_col, predicted_col = f'predicted_{var_name}', f'actual_{var_name}' # Corrected column order\n",
    "    if actual_col in validation_df.columns and predicted_col in validation_df.columns:\n",
    "        temp_compare_df = validation_df[[actual_col, predicted_col]].dropna()\n",
    "        if not temp_compare_df.empty:\n",
    "            mae = mean_absolute_error(temp_compare_df[actual_col], temp_compare_df[predicted_col])\n",
    "            rmse = np.sqrt(mean_squared_error(temp_compare_df[actual_col], temp_compare_df[predicted_col]))\n",
    "            r2 = r2_score(temp_compare_df[actual_col], temp_compare_df[predicted_col])\n",
    "            \n",
    "            print(f\"    - {var_name}:\")\n",
    "            print(f\"        Mean Absolute Error (MAE):    {mae:.4f}\")\n",
    "            print(f\"        Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "            print(f\"        R-squared (R²):               {r2:.4f}\")\n",
    "\n",
    "# Save the final validation results to a CSV file\n",
    "print(f\"\\n--- Step 5: Saving final validation results to {FINAL_VALIDATION_OUTPUT_FILE} ---\")\n",
    "validation_df.to_csv(FINAL_VALIDATION_OUTPUT_FILE)\n",
    "print(\"Save complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae34768b-3db2-4cae-b248-dca24cbbbc22",
   "metadata": {},
   "source": [
    "####  Summary: Why the Model Performed Poorly\n",
    "\n",
    "The high errors and negative R² values are primarily due to **systematic bias between the two datasets** — ERA5 and NASA NEX-GDDP-CMIP6, which are fundamentally different in purpose and construction:\n",
    "\n",
    "---\n",
    "\n",
    "##### 1. Different Dataset Natures\n",
    "\n",
    "- **ERA5 (Reanalysis - \"Corrected Past\")**:  \n",
    "  Assimilates real-world observations (from satellites, stations, etc.) into a physical model to reconstruct the most accurate historical record.\n",
    "\n",
    "- **NASA NEX-GDDP-CMIP6 (Climate Projection - \"Simulated Past\")**:  \n",
    "  A statistically downscaled climate model based on future-focused simulations. Even historical runs are not constrained by real-time observations.\n",
    "\n",
    "---\n",
    "\n",
    "##### 2. Systematic Biases Between Datasets\n",
    "\n",
    "- **Spatial Resolution Mismatch**:  \n",
    "  NASA data is derived from coarser-resolution global models. Even with downscaling, it smooths over fine-grained, local effects that ERA5 captures (e.g., urban heat island, lakes).\n",
    "\n",
    "- **Different Physical Models & Parametrizations**:  \n",
    "  The core physics, assumptions, and parameter choices vary, introducing consistent biases (e.g., systematically warmer or windier).\n",
    "\n",
    "- **Extreme Events Are Muted**:  \n",
    "  NASA data tends to underrepresent the magnitude of extremes (e.g., strong wind gusts), leading to large prediction errors compared to ERA5.\n",
    "\n",
    "---\n",
    "\n",
    "##### 3. Linear Model Breakdown\n",
    "\n",
    "- **Linear Regression Assumption Fails**:  \n",
    "  The model assumes a stable, linear relationship (e.g., `ERA5 = m * NASA + c`) — but the real relationship is complex, biased, and not linear.\n",
    "\n",
    "- **Negative R² for Wind & Humidity**:  \n",
    "  This means the model performed *worse* than simply predicting the average — a strong indicator of structural model failure.\n",
    "\n",
    "---\n",
    "\n",
    "##### 4. Temperature's \"Okay\" R² is Misleading\n",
    "\n",
    "- **R² = 0.41** looks decent, but it mostly captures the **daily cycle** (diurnal pattern), not true predictive accuracy.\n",
    "\n",
    "- **MAE = 7.72°C** is still high, revealing major mismatches due to dataset bias — the model gets the *shape* of the day, but not the *actual values*.\n",
    "\n",
    "---\n",
    "\n",
    "#####  TL;DR\n",
    "\n",
    "We're translating between two fundamentally different \"languages\" of climate data using a basic dictionary (linear regression). But these datasets differ in grammar, vocabulary, and purpose.\n",
    "\n",
    "> **You need a smarter translator** — like anomaly correction or bias-aware models — that understands the context and systematic differences between datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0834aa-6d1b-4c65-8364-fb3d78176615",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
